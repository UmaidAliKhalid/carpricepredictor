{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Name:  Umaid Ali Khalid\n",
    "\n",
    "###  This exericse will take you through the complete cycle of loading, exploring, and preprocessing data, training and testing a a basic multilayer perceptron neural networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 – Data Acquisition\n",
    "Load the training data 'house_prices_train.csv' into a dataframe. Explore the data to get a better understanding of its structure and any data preparation steps that you need to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import any required libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1460 rows and 81 columns.\n"
     ]
    }
   ],
   "source": [
    "#Load the data and view the dimensions\n",
    "\n",
    "file     = 'house_prices_train.csv'\n",
    "data     = pd.read_csv(file)\n",
    "data_dim = data.shape\n",
    "\n",
    "print ('There are {} rows and {} columns.'.format(data_dim[0], data_dim[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets view samples of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view a few observations\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use your intuition!\n",
    "At first glance is there any field that, without a doubt, will not contribute to the predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1: Remove/exclude any unnecessary field(s) that will not contribute towards the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['Id']\n",
    "del data['Alley']\n",
    "del data['FireplaceQu']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 – Data Exploration\n",
    "- Gather summary/descriptive statistics and inspect **all the fields**. This can help you to identify outliers and detect any inconsistencies\n",
    "- View the frequency of missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2: Gather descriptive statistics to view the range of values in each field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>MSSubClass</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>56.897260</td>\n",
       "      <td>42.300571</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LotFrontage</td>\n",
       "      <td>1201.0</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>21.0</td>\n",
       "      <td>59.00</td>\n",
       "      <td>69.0</td>\n",
       "      <td>80.00</td>\n",
       "      <td>313.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LotArea</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>7553.50</td>\n",
       "      <td>9478.5</td>\n",
       "      <td>11601.50</td>\n",
       "      <td>215245.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OverallQual</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OverallCond</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>YearBuilt</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1954.00</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>YearRemodAdd</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>1967.00</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>2004.00</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MasVnrArea</td>\n",
       "      <td>1452.0</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.00</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BsmtFinSF1</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>383.5</td>\n",
       "      <td>712.25</td>\n",
       "      <td>5644.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BsmtFinSF2</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>46.549315</td>\n",
       "      <td>161.319273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1474.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BsmtUnfSF</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>567.240411</td>\n",
       "      <td>441.866955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223.00</td>\n",
       "      <td>477.5</td>\n",
       "      <td>808.00</td>\n",
       "      <td>2336.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TotalBsmtSF</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>1057.429452</td>\n",
       "      <td>438.705324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>795.75</td>\n",
       "      <td>991.5</td>\n",
       "      <td>1298.25</td>\n",
       "      <td>6110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1stFlrSF</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>1162.626712</td>\n",
       "      <td>386.587738</td>\n",
       "      <td>334.0</td>\n",
       "      <td>882.00</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>1391.25</td>\n",
       "      <td>4692.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2ndFlrSF</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>346.992466</td>\n",
       "      <td>436.528436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>728.00</td>\n",
       "      <td>2065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LowQualFinSF</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>5.844521</td>\n",
       "      <td>48.623081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>572.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>GrLivArea</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>1515.463699</td>\n",
       "      <td>525.480383</td>\n",
       "      <td>334.0</td>\n",
       "      <td>1129.50</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>1776.75</td>\n",
       "      <td>5642.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BsmtFullBath</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>0.425342</td>\n",
       "      <td>0.518911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BsmtHalfBath</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>0.057534</td>\n",
       "      <td>0.238753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>FullBath</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>1.565068</td>\n",
       "      <td>0.550916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HalfBath</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>0.382877</td>\n",
       "      <td>0.502885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BedroomAbvGr</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>2.866438</td>\n",
       "      <td>0.815778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KitchenAbvGr</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>1.046575</td>\n",
       "      <td>0.220338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TotRmsAbvGrd</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>6.517808</td>\n",
       "      <td>1.625393</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Fireplaces</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>0.613014</td>\n",
       "      <td>0.644666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>GarageYrBlt</td>\n",
       "      <td>1379.0</td>\n",
       "      <td>1978.506164</td>\n",
       "      <td>24.689725</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>1961.00</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>2002.00</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>GarageCars</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>1.767123</td>\n",
       "      <td>0.747315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>GarageArea</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>472.980137</td>\n",
       "      <td>213.804841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>334.50</td>\n",
       "      <td>480.0</td>\n",
       "      <td>576.00</td>\n",
       "      <td>1418.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>WoodDeckSF</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.00</td>\n",
       "      <td>857.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OpenPorchSF</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>68.00</td>\n",
       "      <td>547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>EnclosedPorch</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>552.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3SsnPorch</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ScreenPorch</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PoolArea</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>738.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MiscVal</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MoSold</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>YrSold</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>2007.00</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SalePrice</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>180921.195890</td>\n",
       "      <td>79442.502883</td>\n",
       "      <td>34900.0</td>\n",
       "      <td>129975.00</td>\n",
       "      <td>163000.0</td>\n",
       "      <td>214000.00</td>\n",
       "      <td>755000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count           mean           std      min        25%  \\\n",
       "MSSubClass     1460.0      56.897260     42.300571     20.0      20.00   \n",
       "LotFrontage    1201.0      70.049958     24.284752     21.0      59.00   \n",
       "LotArea        1460.0   10516.828082   9981.264932   1300.0    7553.50   \n",
       "OverallQual    1460.0       6.099315      1.382997      1.0       5.00   \n",
       "OverallCond    1460.0       5.575342      1.112799      1.0       5.00   \n",
       "YearBuilt      1460.0    1971.267808     30.202904   1872.0    1954.00   \n",
       "YearRemodAdd   1460.0    1984.865753     20.645407   1950.0    1967.00   \n",
       "MasVnrArea     1452.0     103.685262    181.066207      0.0       0.00   \n",
       "BsmtFinSF1     1460.0     443.639726    456.098091      0.0       0.00   \n",
       "BsmtFinSF2     1460.0      46.549315    161.319273      0.0       0.00   \n",
       "BsmtUnfSF      1460.0     567.240411    441.866955      0.0     223.00   \n",
       "TotalBsmtSF    1460.0    1057.429452    438.705324      0.0     795.75   \n",
       "1stFlrSF       1460.0    1162.626712    386.587738    334.0     882.00   \n",
       "2ndFlrSF       1460.0     346.992466    436.528436      0.0       0.00   \n",
       "LowQualFinSF   1460.0       5.844521     48.623081      0.0       0.00   \n",
       "GrLivArea      1460.0    1515.463699    525.480383    334.0    1129.50   \n",
       "BsmtFullBath   1460.0       0.425342      0.518911      0.0       0.00   \n",
       "BsmtHalfBath   1460.0       0.057534      0.238753      0.0       0.00   \n",
       "FullBath       1460.0       1.565068      0.550916      0.0       1.00   \n",
       "HalfBath       1460.0       0.382877      0.502885      0.0       0.00   \n",
       "BedroomAbvGr   1460.0       2.866438      0.815778      0.0       2.00   \n",
       "KitchenAbvGr   1460.0       1.046575      0.220338      0.0       1.00   \n",
       "TotRmsAbvGrd   1460.0       6.517808      1.625393      2.0       5.00   \n",
       "Fireplaces     1460.0       0.613014      0.644666      0.0       0.00   \n",
       "GarageYrBlt    1379.0    1978.506164     24.689725   1900.0    1961.00   \n",
       "GarageCars     1460.0       1.767123      0.747315      0.0       1.00   \n",
       "GarageArea     1460.0     472.980137    213.804841      0.0     334.50   \n",
       "WoodDeckSF     1460.0      94.244521    125.338794      0.0       0.00   \n",
       "OpenPorchSF    1460.0      46.660274     66.256028      0.0       0.00   \n",
       "EnclosedPorch  1460.0      21.954110     61.119149      0.0       0.00   \n",
       "3SsnPorch      1460.0       3.409589     29.317331      0.0       0.00   \n",
       "ScreenPorch    1460.0      15.060959     55.757415      0.0       0.00   \n",
       "PoolArea       1460.0       2.758904     40.177307      0.0       0.00   \n",
       "MiscVal        1460.0      43.489041    496.123024      0.0       0.00   \n",
       "MoSold         1460.0       6.321918      2.703626      1.0       5.00   \n",
       "YrSold         1460.0    2007.815753      1.328095   2006.0    2007.00   \n",
       "SalePrice      1460.0  180921.195890  79442.502883  34900.0  129975.00   \n",
       "\n",
       "                    50%        75%       max  \n",
       "MSSubClass         50.0      70.00     190.0  \n",
       "LotFrontage        69.0      80.00     313.0  \n",
       "LotArea          9478.5   11601.50  215245.0  \n",
       "OverallQual         6.0       7.00      10.0  \n",
       "OverallCond         5.0       6.00       9.0  \n",
       "YearBuilt        1973.0    2000.00    2010.0  \n",
       "YearRemodAdd     1994.0    2004.00    2010.0  \n",
       "MasVnrArea          0.0     166.00    1600.0  \n",
       "BsmtFinSF1        383.5     712.25    5644.0  \n",
       "BsmtFinSF2          0.0       0.00    1474.0  \n",
       "BsmtUnfSF         477.5     808.00    2336.0  \n",
       "TotalBsmtSF       991.5    1298.25    6110.0  \n",
       "1stFlrSF         1087.0    1391.25    4692.0  \n",
       "2ndFlrSF            0.0     728.00    2065.0  \n",
       "LowQualFinSF        0.0       0.00     572.0  \n",
       "GrLivArea        1464.0    1776.75    5642.0  \n",
       "BsmtFullBath        0.0       1.00       3.0  \n",
       "BsmtHalfBath        0.0       0.00       2.0  \n",
       "FullBath            2.0       2.00       3.0  \n",
       "HalfBath            0.0       1.00       2.0  \n",
       "BedroomAbvGr        3.0       3.00       8.0  \n",
       "KitchenAbvGr        1.0       1.00       3.0  \n",
       "TotRmsAbvGrd        6.0       7.00      14.0  \n",
       "Fireplaces          1.0       1.00       3.0  \n",
       "GarageYrBlt      1980.0    2002.00    2010.0  \n",
       "GarageCars          2.0       2.00       4.0  \n",
       "GarageArea        480.0     576.00    1418.0  \n",
       "WoodDeckSF          0.0     168.00     857.0  \n",
       "OpenPorchSF        25.0      68.00     547.0  \n",
       "EnclosedPorch       0.0       0.00     552.0  \n",
       "3SsnPorch           0.0       0.00     508.0  \n",
       "ScreenPorch         0.0       0.00     480.0  \n",
       "PoolArea            0.0       0.00     738.0  \n",
       "MiscVal             0.0       0.00   15500.0  \n",
       "MoSold              6.0       8.00      12.0  \n",
       "YrSold           2008.0    2009.00    2010.0  \n",
       "SalePrice      163000.0  214000.00  755000.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3: Show the frequency of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass          0\n",
       "MSZoning            0\n",
       "LotFrontage       259\n",
       "LotArea             0\n",
       "Street              0\n",
       "LotShape            0\n",
       "LandContour         0\n",
       "Utilities           0\n",
       "LotConfig           0\n",
       "LandSlope           0\n",
       "Neighborhood        0\n",
       "Condition1          0\n",
       "Condition2          0\n",
       "BldgType            0\n",
       "HouseStyle          0\n",
       "OverallQual         0\n",
       "OverallCond         0\n",
       "YearBuilt           0\n",
       "YearRemodAdd        0\n",
       "RoofStyle           0\n",
       "RoofMatl            0\n",
       "Exterior1st         0\n",
       "Exterior2nd         0\n",
       "MasVnrType          8\n",
       "MasVnrArea          8\n",
       "ExterQual           0\n",
       "ExterCond           0\n",
       "Foundation          0\n",
       "BsmtQual           37\n",
       "BsmtCond           37\n",
       "BsmtExposure       38\n",
       "BsmtFinType1       37\n",
       "BsmtFinSF1          0\n",
       "BsmtFinType2       38\n",
       "BsmtFinSF2          0\n",
       "BsmtUnfSF           0\n",
       "TotalBsmtSF         0\n",
       "Heating             0\n",
       "HeatingQC           0\n",
       "CentralAir          0\n",
       "Electrical          1\n",
       "1stFlrSF            0\n",
       "2ndFlrSF            0\n",
       "LowQualFinSF        0\n",
       "GrLivArea           0\n",
       "BsmtFullBath        0\n",
       "BsmtHalfBath        0\n",
       "FullBath            0\n",
       "HalfBath            0\n",
       "BedroomAbvGr        0\n",
       "KitchenAbvGr        0\n",
       "KitchenQual         0\n",
       "TotRmsAbvGrd        0\n",
       "Functional          0\n",
       "Fireplaces          0\n",
       "GarageType         81\n",
       "GarageYrBlt        81\n",
       "GarageFinish       81\n",
       "GarageCars          0\n",
       "GarageArea          0\n",
       "GarageQual         81\n",
       "GarageCond         81\n",
       "PavedDrive          0\n",
       "WoodDeckSF          0\n",
       "OpenPorchSF         0\n",
       "EnclosedPorch       0\n",
       "3SsnPorch           0\n",
       "ScreenPorch         0\n",
       "PoolArea            0\n",
       "PoolQC           1453\n",
       "Fence            1179\n",
       "MiscFeature      1406\n",
       "MiscVal             0\n",
       "MoSold              0\n",
       "YrSold              0\n",
       "SaleType            0\n",
       "SaleCondition       0\n",
       "SalePrice           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 81\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4: State your observations about the summary statistics and missing values\n",
    "Note: recall that not all missing values need to be deleted, some of them can be imputed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'>It looks like there are few of the columns that needs to be deleted based on the observation of data and everything else seems alright</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['PoolQC']\n",
    "del data['MiscFeature']\n",
    "#Delete Misc values since misc features are missing\n",
    "del data['MiscVal']\n",
    "del data['Fence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1456</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1457</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1458</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0             60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1             20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2             60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3             70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4             60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "...          ...      ...          ...      ...    ...      ...         ...   \n",
       "1455          60       RL         62.0     7917   Pave      Reg         Lvl   \n",
       "1456          20       RL         85.0    13175   Pave      Reg         Lvl   \n",
       "1457          70       RL         66.0     9042   Pave      Reg         Lvl   \n",
       "1458          20       RL         68.0     9717   Pave      Reg         Lvl   \n",
       "1459          20       RL         75.0     9937   Pave      Reg         Lvl   \n",
       "\n",
       "     Utilities LotConfig LandSlope  ... OpenPorchSF EnclosedPorch 3SsnPorch  \\\n",
       "0       AllPub    Inside       Gtl  ...          61             0         0   \n",
       "1       AllPub       FR2       Gtl  ...           0             0         0   \n",
       "2       AllPub    Inside       Gtl  ...          42             0         0   \n",
       "3       AllPub    Corner       Gtl  ...          35           272         0   \n",
       "4       AllPub       FR2       Gtl  ...          84             0         0   \n",
       "...        ...       ...       ...  ...         ...           ...       ...   \n",
       "1455    AllPub    Inside       Gtl  ...          40             0         0   \n",
       "1456    AllPub    Inside       Gtl  ...           0             0         0   \n",
       "1457    AllPub    Inside       Gtl  ...          60             0         0   \n",
       "1458    AllPub    Inside       Gtl  ...           0           112         0   \n",
       "1459    AllPub    Inside       Gtl  ...          68             0         0   \n",
       "\n",
       "     ScreenPorch PoolArea  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0              0        0       2    2008        WD         Normal    208500  \n",
       "1              0        0       5    2007        WD         Normal    181500  \n",
       "2              0        0       9    2008        WD         Normal    223500  \n",
       "3              0        0       2    2006        WD        Abnorml    140000  \n",
       "4              0        0      12    2008        WD         Normal    250000  \n",
       "...          ...      ...     ...     ...       ...            ...       ...  \n",
       "1455           0        0       8    2007        WD         Normal    175000  \n",
       "1456           0        0       2    2010        WD         Normal    210000  \n",
       "1457           0        0       5    2010        WD         Normal    266500  \n",
       "1458           0        0       4    2010        WD         Normal    142125  \n",
       "1459           0        0       6    2008        WD         Normal    147500  \n",
       "\n",
       "[1460 rows x 74 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5: List the continuous and categorical data and state any discrepancy between the number of expected records in the dataset and the \"count\"  that is reported above. \n",
    "\n",
    "For the fields that are discussed, view `data_description.txt` which explains the range of values for each field. What does this tell you about these 'missing' values. How do you recommend addressing them? **(You do not need to demonstrate your recommendations)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Categorical=data.loc[:,data.dtypes==np.object]\n",
    "Continuous=data.loc[:,data.dtypes!=np.object]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 38 columns):\n",
      "MSZoning         1460 non-null object\n",
      "Street           1460 non-null object\n",
      "LotShape         1460 non-null object\n",
      "LandContour      1460 non-null object\n",
      "Utilities        1460 non-null object\n",
      "LotConfig        1460 non-null object\n",
      "LandSlope        1460 non-null object\n",
      "Neighborhood     1460 non-null object\n",
      "Condition1       1460 non-null object\n",
      "Condition2       1460 non-null object\n",
      "BldgType         1460 non-null object\n",
      "HouseStyle       1460 non-null object\n",
      "RoofStyle        1460 non-null object\n",
      "RoofMatl         1460 non-null object\n",
      "Exterior1st      1460 non-null object\n",
      "Exterior2nd      1460 non-null object\n",
      "MasVnrType       1452 non-null object\n",
      "ExterQual        1460 non-null object\n",
      "ExterCond        1460 non-null object\n",
      "Foundation       1460 non-null object\n",
      "BsmtQual         1423 non-null object\n",
      "BsmtCond         1423 non-null object\n",
      "BsmtExposure     1422 non-null object\n",
      "BsmtFinType1     1423 non-null object\n",
      "BsmtFinType2     1422 non-null object\n",
      "Heating          1460 non-null object\n",
      "HeatingQC        1460 non-null object\n",
      "CentralAir       1460 non-null object\n",
      "Electrical       1459 non-null object\n",
      "KitchenQual      1460 non-null object\n",
      "Functional       1460 non-null object\n",
      "GarageType       1379 non-null object\n",
      "GarageFinish     1379 non-null object\n",
      "GarageQual       1379 non-null object\n",
      "GarageCond       1379 non-null object\n",
      "PavedDrive       1460 non-null object\n",
      "SaleType         1460 non-null object\n",
      "SaleCondition    1460 non-null object\n",
      "dtypes: object(38)\n",
      "memory usage: 433.6+ KB\n"
     ]
    }
   ],
   "source": [
    "Categorical.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 36 columns):\n",
      "MSSubClass       1460 non-null int64\n",
      "LotFrontage      1201 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "MasVnrArea       1452 non-null float64\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Fireplaces       1460 non-null int64\n",
      "GarageYrBlt      1379 non-null float64\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "SalePrice        1460 non-null int64\n",
      "dtypes: float64(3), int64(33)\n",
      "memory usage: 410.8 KB\n"
     ]
    }
   ],
   "source": [
    "Continuous.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Based on the data from Exercise 4</font>\n",
    "### Continuous data has less number of columns compared to Categorical data.\n",
    "### <font color='red'>In categorical data</font>\n",
    "#### Following variable contains missing values:MasVnrType, BsmtQual, BsmtCond, BsmtExposure,BsmtFinType1,BsmtFinType2   \n",
    "### <font color='red'>In continuous data</font>\n",
    "#### Following variable contains missing values:LotFrontage,MasVnrArea, GarageYrBlt     \n",
    "### <font color='green'>How to handle missing data</font>\n",
    "#### To deal with missing data, utilize built in python functions to fill in the missing values such as <font color='red'>interpolation</font>  or delete the columns with most of the missing values that have been done already!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 6: The dependent variable:\n",
    "Are there any discrepancies with the dependent variable? Plot a histogram showing its distribution. Is the distribution skewed?  \n",
    "**Hint:\n",
    "Can a logarithmic scale on y-axis give us a better perspective?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "Sdepend = data[['SalePrice']]\n",
    "Sdepend=Sdepend.to_numpy()\n",
    "plt.title('Distribution of SalePrice (dependent variable)')\n",
    "plt.hist(Sdepend, bins='auto')\n",
    "#plt.plot(trip)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'>Yes, distribution is skewed right</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Sdepend=np.log2(data[['SalePrice']])\n",
    "Sdepend=Sdepend.to_numpy()\n",
    "plt.title('Distribution of SalePrice (dependent variable) with logarithmic scale')\n",
    "plt.hist(Sdepend, bins='auto')\n",
    "#plt.plot(trip)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'>Yes,logarithmic scale on y-axis seems to give us a better perspective</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Pipeline\n",
    "Based on your recommendations above, lets build a pipeline that does the following:\n",
    "- prepare the data and perform data imputation\n",
    "- transform the continuous and categorical data (scaling and encoding respectively)\n",
    "- select the useful features e.g. feature selection, *you can optionally include this in the pipeline or perform this step prior to building the pipeline*\n",
    "- build, train and evaluate the neural network using Keras.\n",
    "- perform hyper-parameter tuning using RandomSearchCV **(optional)**\n",
    "- make predictions with new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 – Data Preparation\n",
    "Here is some helpful information on [preprocessing and feature extraction pipelines in scikit-learn](https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html)\n",
    "\n",
    "<span style=\"color:red\">NOTE: You can modify the cell below to suit your needs. However, ensure that the preprocessing steps that you perform is done in the data frame e.g. `data` </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 7: Impute missing continuous values with the median and scale the data:\n",
    "In the cell below complete the list of \"continuous_features\" with continuous variable column names.  Once you run the pipeline, remove any variable columns that will not go through pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of continuous fields that will be used in the model(except the dependent variable)\n",
    "del Continuous['SalePrice']\n",
    "continuous_features  = list(Continuous.columns)\n",
    "\n",
    "#The tranformer below does both filling in missing values with median of the column and scale the column with StandardScaler\n",
    "continous_transformer = Pipeline(\n",
    "    steps = [\n",
    "    ('imputer', SimpleImputer(strategy = 'median')),\n",
    "    ('scaler', StandardScaler())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 8: Impute missing categoriacal values with the median and scale the data:\n",
    "In the cell below complete the list of \"categorical_features\" with categorical variable column names. Once you run the pipeline, remove any variable columns that will not go through pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the list of categorical fields that will be used in the model\n",
    "categorical_features = list(Categorical.columns)\n",
    "\n",
    "#The tranformer below does both filling in missing values as indicated for the categorical columns and \n",
    "#then transform those columns  into one hot encoded variables\n",
    "categorical_transformer = Pipeline(\n",
    "    steps = [\n",
    "    ('imputer', SimpleImputer(strategy = 'constant', fill_value = 'NotApp')), #Use an alternative value to indicate NA in the dataset\n",
    "    ('onehot', OneHotEncoder(handle_unknown = 'ignore'))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessor   = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('continious', continous_transformer, continuous_features),\n",
    "        ('categorical', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "#NOTE: the steps above will not be performed until we call `fit_transform` (in the next cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 – Data Transformation & Feature Selection\n",
    "Here is some helpful information on [feature selection as part of a pipeline](https://scikit-learn.org/stable/modules/feature_selection.html#feature-selection-as-part-of-a-pipeline). If you add a feature selection algorithm to the pipeline, ensure that it supports regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "data_prep_pipeline  = Pipeline(steps=[('preprocessor', data_preprocessor), #This performs the data preparation steps in the cell above\n",
    "                                      ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l2\",max_iter=2000)))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1          20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2          60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3          70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4          60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... OpenPorchSF EnclosedPorch 3SsnPorch  \\\n",
       "0    AllPub    Inside       Gtl  ...          61             0         0   \n",
       "1    AllPub       FR2       Gtl  ...           0             0         0   \n",
       "2    AllPub    Inside       Gtl  ...          42             0         0   \n",
       "3    AllPub    Corner       Gtl  ...          35           272         0   \n",
       "4    AllPub       FR2       Gtl  ...          84             0         0   \n",
       "\n",
       "  ScreenPorch PoolArea  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0           0        0       2    2008        WD         Normal    208500  \n",
       "1           0        0       5    2007        WD         Normal    181500  \n",
       "2           0        0       9    2008        WD         Normal    223500  \n",
       "3           0        0       2    2006        WD        Abnorml    140000  \n",
       "4           0        0      12    2008        WD         Normal    250000  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data    = data_prep_pipeline.fit_transform(data.iloc[:,:-1], data['SalePrice']) #transform the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 – Building the Model\n",
    "#### Build the neural network using Keras\n",
    "Building a feed forward neural network with: an input layer, hidden layers and one output layer. \n",
    "You only need to provide the hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 9: Build your neural networks model\n",
    "In the cell below complete the section under add hidden (add at least three).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "12/12 [==============================] - 2s 95ms/step - loss: 180421.4844 - mae: 180421.4844 - val_loss: 182181.9531 - val_mae: 182181.9531\n",
      "Epoch 2/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 178206.7103 - mae: 178206.7103 - val_loss: 181206.2812 - val_mae: 181206.2812\n",
      "Epoch 3/200\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 175401.2416 - mae: 175401.2416 - val_loss: 173234.2969 - val_mae: 173234.2969\n",
      "Epoch 4/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 162238.9615 - mae: 162238.9675 - val_loss: 127996.3281 - val_mae: 127996.3281\n",
      "Epoch 5/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 99788.3377 - mae: 99788.3377 - val_loss: 64567.2812 - val_mae: 64567.2812\n",
      "Epoch 6/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 57210.7395 - mae: 57210.7395 - val_loss: 43504.4023 - val_mae: 43504.4023\n",
      "Epoch 7/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 37393.8056 - mae: 37393.8083 - val_loss: 31124.0723 - val_mae: 31124.0723\n",
      "Epoch 8/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 26079.7650 - mae: 26079.7650 - val_loss: 27554.1348 - val_mae: 27554.1348\n",
      "Epoch 9/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 23937.6223 - mae: 23937.6223 - val_loss: 25943.7715 - val_mae: 25943.7715\n",
      "Epoch 10/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 22841.4093 - mae: 22841.4093 - val_loss: 24874.8691 - val_mae: 24874.8691\n",
      "Epoch 11/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 21118.2434 - mae: 21118.2434 - val_loss: 23971.0566 - val_mae: 23971.0566\n",
      "Epoch 12/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 19701.1578 - mae: 19701.1578 - val_loss: 23619.1465 - val_mae: 23619.1465\n",
      "Epoch 13/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 19166.0027 - mae: 19166.0027 - val_loss: 23558.0098 - val_mae: 23558.0098\n",
      "Epoch 14/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 19071.8018 - mae: 19071.8015 - val_loss: 23300.9648 - val_mae: 23300.9648\n",
      "Epoch 15/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 18019.1446 - mae: 18019.1446 - val_loss: 21989.9805 - val_mae: 21989.9805\n",
      "Epoch 16/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 18823.6348 - mae: 18823.6348 - val_loss: 21752.9141 - val_mae: 21752.9141\n",
      "Epoch 17/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 17340.0966 - mae: 17340.0966 - val_loss: 21467.9492 - val_mae: 21467.9492\n",
      "Epoch 18/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 17281.3725 - mae: 17281.3725 - val_loss: 21207.5215 - val_mae: 21207.5215\n",
      "Epoch 19/200\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 15584.2430 - mae: 15584.2430 - val_loss: 20749.3164 - val_mae: 20749.3164\n",
      "Epoch 20/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 16524.7076 - mae: 16524.7076 - val_loss: 20800.0098 - val_mae: 20800.0098\n",
      "Epoch 21/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 15304.2112 - mae: 15304.2112 - val_loss: 20318.4180 - val_mae: 20318.4180\n",
      "Epoch 22/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 15105.9818 - mae: 15105.9818 - val_loss: 20098.3516 - val_mae: 20098.3516\n",
      "Epoch 23/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 16511.7099 - mae: 16511.7099 - val_loss: 19917.7383 - val_mae: 19917.7383\n",
      "Epoch 24/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 16176.6015 - mae: 16176.6015 - val_loss: 19709.9141 - val_mae: 19709.9141\n",
      "Epoch 25/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 14923.5817 - mae: 14923.5817 - val_loss: 19577.8281 - val_mae: 19577.8281\n",
      "Epoch 26/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 14782.1863 - mae: 14782.1863 - val_loss: 19714.6348 - val_mae: 19714.6348\n",
      "Epoch 27/200\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 15289.9685 - mae: 15289.9685 - val_loss: 19617.1328 - val_mae: 19617.1328\n",
      "Epoch 28/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 14432.8546 - mae: 14432.8546 - val_loss: 19568.4902 - val_mae: 19568.4902\n",
      "Epoch 29/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 14653.7894 - mae: 14653.7894 - val_loss: 20669.1602 - val_mae: 20669.1602\n",
      "Epoch 30/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 15139.4003 - mae: 15139.4003 - val_loss: 19366.7988 - val_mae: 19366.7988\n",
      "Epoch 31/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 14116.9523 - mae: 14116.9523 - val_loss: 19487.8184 - val_mae: 19487.8184\n",
      "Epoch 32/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 14164.9874 - mae: 14164.9872 - val_loss: 19108.0430 - val_mae: 19108.0430\n",
      "Epoch 33/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 14045.0011 - mae: 14045.0011 - val_loss: 19123.0215 - val_mae: 19123.0215\n",
      "Epoch 34/200\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 14626.5895 - mae: 14626.5897 - val_loss: 18852.6992 - val_mae: 18852.6992\n",
      "Epoch 35/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 13313.5998 - mae: 13313.5998 - val_loss: 18948.7676 - val_mae: 18948.7695\n",
      "Epoch 36/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 13925.0554 - mae: 13925.0554 - val_loss: 19032.1719 - val_mae: 19032.1719\n",
      "Epoch 37/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 13519.9543 - mae: 13519.9540 - val_loss: 18844.2715 - val_mae: 18844.2715\n",
      "Epoch 38/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 13272.1946 - mae: 13272.1946 - val_loss: 18694.9512 - val_mae: 18694.9512\n",
      "Epoch 39/200\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 13567.1468 - mae: 13567.1468 - val_loss: 18811.0020 - val_mae: 18811.0020\n",
      "Epoch 40/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 13603.2600 - mae: 13603.2600 - val_loss: 19300.1660 - val_mae: 19300.1660\n",
      "Epoch 41/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 13968.1022 - mae: 13968.1022 - val_loss: 19194.5645 - val_mae: 19194.5645\n",
      "Epoch 42/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 13248.3114 - mae: 13248.3114 - val_loss: 18634.8867 - val_mae: 18634.8867\n",
      "Epoch 43/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 13269.0014 - mae: 13269.0014 - val_loss: 18484.1465 - val_mae: 18484.1465\n",
      "Epoch 44/200\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 14041.2603 - mae: 14041.2603 - val_loss: 19071.2598 - val_mae: 19071.2598\n",
      "Epoch 45/200\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 13860.9247 - mae: 13860.9247 - val_loss: 18491.1602 - val_mae: 18491.1602\n",
      "Epoch 46/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 13342.8568 - mae: 13342.8568 - val_loss: 18435.7012 - val_mae: 18435.7012\n",
      "Epoch 47/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 13439.1660 - mae: 13439.1660 - val_loss: 18302.0645 - val_mae: 18302.0645\n",
      "Epoch 48/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 13215.9241 - mae: 13215.9241 - val_loss: 18421.3281 - val_mae: 18421.3281\n",
      "Epoch 49/200\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 12617.9760 - mae: 12617.9760 - val_loss: 18321.9023 - val_mae: 18321.9023\n",
      "Epoch 50/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 12599.2267 - mae: 12599.2270 - val_loss: 18416.8867 - val_mae: 18416.8867\n",
      "Epoch 51/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 13079.5766 - mae: 13079.5766 - val_loss: 18920.6035 - val_mae: 18920.6016\n",
      "Epoch 52/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 13203.7360 - mae: 13203.7360 - val_loss: 18384.9043 - val_mae: 18384.9043\n",
      "Epoch 53/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 12833.3720 - mae: 12833.3721 - val_loss: 18334.6465 - val_mae: 18334.6465\n",
      "Epoch 54/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 13176.7157 - mae: 13176.7157 - val_loss: 18246.5410 - val_mae: 18246.5410\n",
      "Epoch 55/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 14584.7670 - mae: 14584.7670 - val_loss: 18682.1465 - val_mae: 18682.1465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 12277.1433 - mae: 12277.1433 - val_loss: 18852.5059 - val_mae: 18852.5059\n",
      "Epoch 57/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 12918.1328 - mae: 12918.1328 - val_loss: 18020.7520 - val_mae: 18020.7520\n",
      "Epoch 58/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 13310.6113 - mae: 13310.6113 - val_loss: 18063.0117 - val_mae: 18063.0117\n",
      "Epoch 59/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 11651.7867 - mae: 11651.7867 - val_loss: 18318.9258 - val_mae: 18318.9258\n",
      "Epoch 60/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 13555.8187 - mae: 13555.8187 - val_loss: 18012.5957 - val_mae: 18012.5957\n",
      "Epoch 61/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 11844.2749 - mae: 11844.2749 - val_loss: 18551.0547 - val_mae: 18551.0547\n",
      "Epoch 62/200\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 12883.7880 - mae: 12883.7880 - val_loss: 18351.2285 - val_mae: 18351.2305\n",
      "Epoch 63/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 12762.7917 - mae: 12762.7917 - val_loss: 18179.2227 - val_mae: 18179.2227\n",
      "Epoch 64/200\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 12300.2388 - mae: 12300.2388 - val_loss: 17982.0430 - val_mae: 17982.0430\n",
      "Epoch 65/200\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 11800.5699 - mae: 11800.5699 - val_loss: 18014.6992 - val_mae: 18014.6992\n",
      "Epoch 66/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 11202.3700 - mae: 11202.3700 - val_loss: 18055.3418 - val_mae: 18055.3418\n",
      "Epoch 67/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 11670.8370 - mae: 11670.8370 - val_loss: 17885.4180 - val_mae: 17885.4180\n",
      "Epoch 68/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 12822.4165 - mae: 12822.4165 - val_loss: 18518.0293 - val_mae: 18518.0293\n",
      "Epoch 69/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 12707.2200 - mae: 12707.2200 - val_loss: 18126.9395 - val_mae: 18126.9395\n",
      "Epoch 70/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 11844.6212 - mae: 11844.6212 - val_loss: 17812.9512 - val_mae: 17812.9512\n",
      "Epoch 71/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 12658.3349 - mae: 12658.3349 - val_loss: 17985.6680 - val_mae: 17985.6680\n",
      "Epoch 72/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 13123.8758 - mae: 13123.8758 - val_loss: 18032.3633 - val_mae: 18032.3633\n",
      "Epoch 73/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 11991.6374 - mae: 11991.6374 - val_loss: 18007.6758 - val_mae: 18007.6758\n",
      "Epoch 74/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 12162.7790 - mae: 12162.7790 - val_loss: 17861.2344 - val_mae: 17861.2344\n",
      "Epoch 75/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 13089.3845 - mae: 13089.3845 - val_loss: 17769.0039 - val_mae: 17769.0039\n",
      "Epoch 76/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 12394.3658 - mae: 12394.3658 - val_loss: 18727.1719 - val_mae: 18727.1719\n",
      "Epoch 77/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 12155.8370 - mae: 12155.8370 - val_loss: 17731.1113 - val_mae: 17731.1113\n",
      "Epoch 78/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 12993.6846 - mae: 12993.6834 - val_loss: 17938.5449 - val_mae: 17938.5449\n",
      "Epoch 79/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 11642.9734 - mae: 11642.9734 - val_loss: 17957.5684 - val_mae: 17957.5684\n",
      "Epoch 80/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 11759.2306 - mae: 11759.2306 - val_loss: 17717.0781 - val_mae: 17717.0781\n",
      "Epoch 81/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 11564.4298 - mae: 11564.4292 - val_loss: 18020.1250 - val_mae: 18020.1250\n",
      "Epoch 82/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 11393.1559 - mae: 11393.1559 - val_loss: 17768.8672 - val_mae: 17768.8672\n",
      "Epoch 83/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 12179.5162 - mae: 12179.5162 - val_loss: 18139.2031 - val_mae: 18139.2031\n",
      "Epoch 84/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 11014.5982 - mae: 11014.5982 - val_loss: 17793.2363 - val_mae: 17793.2363\n",
      "Epoch 85/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 10563.7985 - mae: 10563.7985 - val_loss: 18288.6738 - val_mae: 18288.6738\n",
      "Epoch 86/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 12535.4645 - mae: 12535.4645 - val_loss: 17894.0312 - val_mae: 17894.0293\n",
      "Epoch 87/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 11674.3410 - mae: 11674.3410 - val_loss: 17819.0625 - val_mae: 17819.0625\n",
      "Epoch 88/200\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 11310.7577 - mae: 11310.7577 - val_loss: 17696.6719 - val_mae: 17696.6699\n",
      "Epoch 89/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 11832.4875 - mae: 11832.4873 - val_loss: 17895.0371 - val_mae: 17895.0371\n",
      "Epoch 90/200\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 12714.7247 - mae: 12714.7248 - val_loss: 17680.0312 - val_mae: 17680.0312\n",
      "Epoch 91/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 11221.8757 - mae: 11221.8755 - val_loss: 17714.1270 - val_mae: 17714.1270\n",
      "Epoch 92/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 12384.2502 - mae: 12384.2502 - val_loss: 18099.4805 - val_mae: 18099.4805\n",
      "Epoch 93/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 10803.5055 - mae: 10803.5056 - val_loss: 17722.8047 - val_mae: 17722.8047\n",
      "Epoch 94/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 10957.2273 - mae: 10957.2273 - val_loss: 17918.9668 - val_mae: 17918.9668\n",
      "Epoch 95/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 11540.0863 - mae: 11540.0863 - val_loss: 17886.3242 - val_mae: 17886.3242\n",
      "Epoch 96/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 11300.4527 - mae: 11300.4527 - val_loss: 18290.1094 - val_mae: 18290.1094\n",
      "Epoch 97/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 11185.3480 - mae: 11185.3480 - val_loss: 17643.2227 - val_mae: 17643.2227\n",
      "Epoch 98/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 11145.7504 - mae: 11145.7504 - val_loss: 18211.7871 - val_mae: 18211.7871\n",
      "Epoch 99/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 12305.3391 - mae: 12305.3395 - val_loss: 17623.0938 - val_mae: 17623.0938\n",
      "Epoch 100/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 10314.6229 - mae: 10314.6229 - val_loss: 17634.7578 - val_mae: 17634.7578\n",
      "Epoch 101/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 10591.6125 - mae: 10591.6125 - val_loss: 19073.1582 - val_mae: 19073.1582\n",
      "Epoch 102/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 12906.4978 - mae: 12906.4978 - val_loss: 17608.9238 - val_mae: 17608.9238\n",
      "Epoch 103/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 12034.4768 - mae: 12034.4766 - val_loss: 17960.9727 - val_mae: 17960.9727\n",
      "Epoch 104/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 10822.5957 - mae: 10822.5957 - val_loss: 17588.9102 - val_mae: 17588.9102\n",
      "Epoch 105/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 10537.7974 - mae: 10537.7974 - val_loss: 17582.7637 - val_mae: 17582.7637\n",
      "Epoch 106/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 12221.3688 - mae: 12221.3688 - val_loss: 18045.3633 - val_mae: 18045.3633\n",
      "Epoch 107/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 10722.7314 - mae: 10722.7314 - val_loss: 17839.8047 - val_mae: 17839.8047\n",
      "Epoch 108/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 10545.8150 - mae: 10545.8144 - val_loss: 17501.7812 - val_mae: 17501.7812\n",
      "Epoch 109/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 10923.3242 - mae: 10923.3242 - val_loss: 17771.3770 - val_mae: 17771.3770\n",
      "Epoch 110/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 12197.2575 - mae: 12197.2575 - val_loss: 17737.4238 - val_mae: 17737.4238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 10649.0122 - mae: 10649.0122 - val_loss: 18258.4785 - val_mae: 18258.4785\n",
      "Epoch 112/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 11159.4729 - mae: 11159.4729 - val_loss: 17813.9434 - val_mae: 17813.9434\n",
      "Epoch 113/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 10192.3699 - mae: 10192.3698 - val_loss: 18023.7637 - val_mae: 18023.7637\n",
      "Epoch 114/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 10518.5142 - mae: 10518.5142 - val_loss: 17883.7578 - val_mae: 17883.7578\n",
      "Epoch 115/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 10809.4289 - mae: 10809.4293 - val_loss: 17620.9844 - val_mae: 17620.9844\n",
      "Epoch 116/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 11687.1893 - mae: 11687.1893 - val_loss: 17814.3203 - val_mae: 17814.3203\n",
      "Epoch 117/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 10562.8432 - mae: 10562.8432 - val_loss: 17704.7285 - val_mae: 17704.7285\n",
      "Epoch 118/200\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 10505.2095 - mae: 10505.2095 - val_loss: 17547.8594 - val_mae: 17547.8594\n",
      "Epoch 119/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 10617.3601 - mae: 10617.3601 - val_loss: 17931.5664 - val_mae: 17931.5664\n",
      "Epoch 120/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 9868.0431 - mae: 9868.0431 - val_loss: 17647.4688 - val_mae: 17647.4688\n",
      "Epoch 121/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 12467.0406 - mae: 12467.0416 - val_loss: 17629.2402 - val_mae: 17629.2402\n",
      "Epoch 122/200\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 10799.7448 - mae: 10799.7448 - val_loss: 18235.1152 - val_mae: 18235.1152\n",
      "Epoch 123/200\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 10067.6522 - mae: 10067.6520 - val_loss: 17466.7598 - val_mae: 17466.7598\n",
      "Epoch 124/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 10283.9927 - mae: 10283.9927 - val_loss: 17565.7949 - val_mae: 17565.7949\n",
      "Epoch 125/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 10728.8591 - mae: 10728.8595 - val_loss: 17956.5430 - val_mae: 17956.5430\n",
      "Epoch 126/200\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 11747.4490 - mae: 11747.4490 - val_loss: 17782.5098 - val_mae: 17782.5098\n",
      "Epoch 127/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 10072.3538 - mae: 10072.3530 - val_loss: 17706.3359 - val_mae: 17706.3359\n",
      "Epoch 128/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 9810.7322 - mae: 9810.7322 - val_loss: 17796.0684 - val_mae: 17796.0684\n",
      "Epoch 129/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 10311.1595 - mae: 10311.1595 - val_loss: 18111.7129 - val_mae: 18111.7129\n",
      "Epoch 130/200\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 10832.2411 - mae: 10832.2411 - val_loss: 17655.1641 - val_mae: 17655.1641\n",
      "Epoch 131/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 10285.7276 - mae: 10285.7276 - val_loss: 17846.6465 - val_mae: 17846.6465\n",
      "Epoch 132/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 9758.6860 - mae: 9758.6860 - val_loss: 17550.2363 - val_mae: 17550.2363\n",
      "Epoch 133/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 10239.6032 - mae: 10239.6032 - val_loss: 18141.6270 - val_mae: 18141.6270\n",
      "Epoch 134/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 11360.6992 - mae: 11360.6992 - val_loss: 18123.0566 - val_mae: 18123.0566\n",
      "Epoch 135/200\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 10184.9834 - mae: 10184.9834 - val_loss: 17646.1953 - val_mae: 17646.1953\n",
      "Epoch 136/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 9808.0780 - mae: 9808.0780 - val_loss: 17584.7285 - val_mae: 17584.7285\n",
      "Epoch 137/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 10555.7721 - mae: 10555.7721 - val_loss: 18830.4648 - val_mae: 18830.4648\n",
      "Epoch 138/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 11003.1545 - mae: 11003.1545 - val_loss: 17720.1191 - val_mae: 17720.1191\n",
      "Epoch 139/200\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 10679.6222 - mae: 10679.6222 - val_loss: 17538.0586 - val_mae: 17538.0586\n",
      "Epoch 140/200\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 9733.9084 - mae: 9733.9084 - val_loss: 17932.4375 - val_mae: 17932.4375\n",
      "Epoch 141/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 10189.7591 - mae: 10189.7593 - val_loss: 17596.0762 - val_mae: 17596.0762\n",
      "Epoch 142/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 9425.7352 - mae: 9425.7351 - val_loss: 17811.8164 - val_mae: 17811.8164\n",
      "Epoch 143/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 9802.9485 - mae: 9802.9485 - val_loss: 18227.9863 - val_mae: 18227.9863\n",
      "Epoch 144/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 9822.5592 - mae: 9822.5596 - val_loss: 17602.7266 - val_mae: 17602.7266\n",
      "Epoch 145/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 10468.9825 - mae: 10468.9824 - val_loss: 17658.3340 - val_mae: 17658.3340\n",
      "Epoch 146/200\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 10907.4567 - mae: 10907.4567 - val_loss: 17491.3086 - val_mae: 17491.3086\n",
      "Epoch 147/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 9530.6295 - mae: 9530.6297 - val_loss: 17672.4414 - val_mae: 17672.4414\n",
      "Epoch 148/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 9783.0527 - mae: 9783.0527 - val_loss: 17609.5957 - val_mae: 17609.5957\n",
      "Epoch 149/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 9353.9671 - mae: 9353.9671 - val_loss: 17646.4863 - val_mae: 17646.4863\n",
      "Epoch 150/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 9302.1111 - mae: 9302.1111 - val_loss: 17796.0723 - val_mae: 17796.0723\n",
      "Epoch 151/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 10254.5186 - mae: 10254.5186 - val_loss: 17842.2656 - val_mae: 17842.2656\n",
      "Epoch 152/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 10263.0310 - mae: 10263.0310 - val_loss: 17707.9180 - val_mae: 17707.9180\n",
      "Epoch 153/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 9868.3701 - mae: 9868.3705 - val_loss: 17698.0293 - val_mae: 17698.0293\n",
      "Epoch 154/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 10524.0661 - mae: 10524.0661 - val_loss: 17797.5410 - val_mae: 17797.5410\n",
      "Epoch 155/200\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 10450.4670 - mae: 10450.4670 - val_loss: 18683.8359 - val_mae: 18683.8359\n",
      "Epoch 156/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 11760.7552 - mae: 11760.7550 - val_loss: 17580.3398 - val_mae: 17580.3398\n",
      "Epoch 157/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 8972.3418 - mae: 8972.3418 - val_loss: 17834.5156 - val_mae: 17834.5156\n",
      "Epoch 158/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 9142.5471 - mae: 9142.5471 - val_loss: 17970.3906 - val_mae: 17970.3906\n",
      "Epoch 159/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 9885.5679 - mae: 9885.5679 - val_loss: 17741.6602 - val_mae: 17741.6602\n",
      "Epoch 160/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 9312.8803 - mae: 9312.8803 - val_loss: 17636.5137 - val_mae: 17636.5137\n",
      "Epoch 161/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 8803.7737 - mae: 8803.7737 - val_loss: 17698.8828 - val_mae: 17698.8828\n",
      "Epoch 162/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 9312.1473 - mae: 9312.1469 - val_loss: 17529.5234 - val_mae: 17529.5234\n",
      "Epoch 163/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 9111.8576 - mae: 9111.8576 - val_loss: 17676.5234 - val_mae: 17676.5234\n",
      "Epoch 164/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 9062.1642 - mae: 9062.1642 - val_loss: 18054.1777 - val_mae: 18054.1777\n",
      "Epoch 165/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 9409.3909 - mae: 9409.3912 - val_loss: 17662.9590 - val_mae: 17662.9590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 9137.2058 - mae: 9137.2058 - val_loss: 17762.6777 - val_mae: 17762.6777\n",
      "Epoch 167/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 9461.2948 - mae: 9461.2948 - val_loss: 17759.2578 - val_mae: 17759.2578\n",
      "Epoch 168/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 8479.7082 - mae: 8479.7086 - val_loss: 17682.9434 - val_mae: 17682.9434\n",
      "Epoch 169/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 8985.5848 - mae: 8985.5848 - val_loss: 17599.4238 - val_mae: 17599.4238\n",
      "Epoch 170/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 8125.0123 - mae: 8125.0123 - val_loss: 17603.5820 - val_mae: 17603.5820\n",
      "Epoch 171/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 8046.9729 - mae: 8046.9729 - val_loss: 17684.4785 - val_mae: 17684.4785\n",
      "Epoch 172/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 9166.0955 - mae: 9166.0955 - val_loss: 17694.6582 - val_mae: 17694.6582\n",
      "Epoch 173/200\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 9824.9331 - mae: 9824.9331 - val_loss: 17635.9922 - val_mae: 17635.9922\n",
      "Epoch 174/200\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 8197.8101 - mae: 8197.8101 - val_loss: 17707.1367 - val_mae: 17707.1367\n",
      "Epoch 175/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 9071.7968 - mae: 9071.7968 - val_loss: 17685.4043 - val_mae: 17685.4043\n",
      "Epoch 176/200\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 8299.2916 - mae: 8299.2917 - val_loss: 17663.1348 - val_mae: 17663.1348\n",
      "Epoch 177/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 8300.7076 - mae: 8300.7076 - val_loss: 17951.3457 - val_mae: 17951.3457\n",
      "Epoch 178/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 8719.7846 - mae: 8719.7846 - val_loss: 18152.0859 - val_mae: 18152.0859\n",
      "Epoch 179/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 10018.3262 - mae: 10018.3261 - val_loss: 17949.8223 - val_mae: 17949.8223\n",
      "Epoch 180/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 9007.2081 - mae: 9007.2080 - val_loss: 17688.8691 - val_mae: 17688.8691\n",
      "Epoch 181/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 9341.0146 - mae: 9341.0146 - val_loss: 17611.7461 - val_mae: 17611.7461\n",
      "Epoch 182/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 8481.4772 - mae: 8481.4772 - val_loss: 17579.5605 - val_mae: 17579.5605\n",
      "Epoch 183/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 9523.0823 - mae: 9523.0823 - val_loss: 17640.0293 - val_mae: 17640.0293\n",
      "Epoch 184/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 7714.8243 - mae: 7714.8243 - val_loss: 17693.3516 - val_mae: 17693.3516\n",
      "Epoch 185/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 8640.1851 - mae: 8640.1851 - val_loss: 17751.9062 - val_mae: 17751.9062\n",
      "Epoch 186/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 8689.2710 - mae: 8689.2710 - val_loss: 17897.4082 - val_mae: 17897.4082\n",
      "Epoch 187/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 9156.1753 - mae: 9156.1753 - val_loss: 17644.6270 - val_mae: 17644.6270\n",
      "Epoch 188/200\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 9135.5640 - mae: 9135.5640 - val_loss: 17595.8320 - val_mae: 17595.8320\n",
      "Epoch 189/200\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 8459.7844 - mae: 8459.7844 - val_loss: 17614.9453 - val_mae: 17614.9453\n",
      "Epoch 190/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 7835.8293 - mae: 7835.8293 - val_loss: 17978.8438 - val_mae: 17978.8438\n",
      "Epoch 191/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 8810.3640 - mae: 8810.3640 - val_loss: 17916.8828 - val_mae: 17916.8828\n",
      "Epoch 192/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 7677.4755 - mae: 7677.4755 - val_loss: 17709.5625 - val_mae: 17709.5625\n",
      "Epoch 193/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 8822.2872 - mae: 8822.2873 - val_loss: 17867.4668 - val_mae: 17867.4668\n",
      "Epoch 194/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 8502.8125 - mae: 8502.8125 - val_loss: 17850.6543 - val_mae: 17850.6543\n",
      "Epoch 195/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 8715.5584 - mae: 8715.5584 - val_loss: 17789.3027 - val_mae: 17789.3027\n",
      "Epoch 196/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 8052.9765 - mae: 8052.9765 - val_loss: 17588.0488 - val_mae: 17588.0488\n",
      "Epoch 197/200\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 9198.0893 - mae: 9198.0893 - val_loss: 17516.5195 - val_mae: 17516.5195\n",
      "Epoch 198/200\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 7827.1867 - mae: 7827.1867 - val_loss: 17692.4219 - val_mae: 17692.4219\n",
      "Epoch 199/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 8169.0466 - mae: 8169.0466 - val_loss: 17761.2227 - val_mae: 17761.2227\n",
      "Epoch 200/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 8335.9038 - mae: 8335.9038 - val_loss: 17706.8047 - val_mae: 17706.8047\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame(transformed_data.toarray()) #this is the transformed data from the pipeline\n",
    "y = data['SalePrice'] #this is the output\n",
    "\n",
    "#Build a sequential model with at least three dense layers (you can add more layers as needed)\n",
    "#Note: you can also add this keras model to the data preprocessing pipeline but we can skip that step for now.\n",
    "ffnn_model = Sequential()\n",
    "## Add hidden layers, one line at time, below\n",
    "ffnn_model.add(Dense(1024,activation='relu'))\n",
    "ffnn_model.add(Dense(512,activation='relu'))\n",
    "ffnn_model.add(Dense(128,activation='relu'))\n",
    "ffnn_model.add(Dense(64,activation='relu'))\n",
    "ffnn_model.add(Dense(32,activation='relu'))\n",
    "ffnn_model.add(Dense(16,activation='relu'))\n",
    "#Here is the oddput layer\n",
    "ffnn_model.add(Dense(1, activation='linear'))\n",
    "\n",
    "\n",
    "\n",
    "#There are options you may want to change and try to improve performance.\n",
    "ffnn_model.compile(optimizer= 'adam', \n",
    "                   loss= 'mean_absolute_error', \n",
    "                   metrics= 'mae'  \n",
    "                  )\n",
    "\n",
    "ffnn_history = ffnn_model.fit(X, y, \n",
    "                              validation_split= 0.2, \n",
    "                              epochs= 200, \n",
    "                              batch_size= 100,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now let us Visualize the training and validation loss\n",
    "plt.plot(ffnn_history.history['loss'], 'b', ffnn_history.history['val_loss'], 'orange')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's use the neural network to make predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 10: Load the test data\n",
    "\n",
    "Now load the data from `house_prices_test.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1459 rows and 80 columns.\n"
     ]
    }
   ],
   "source": [
    "#Load the data and view the dimensions\n",
    "\n",
    "file     = 'house_prices_test.csv'\n",
    "data2     = pd.read_csv(file)\n",
    "data_dim = data2.shape\n",
    "\n",
    "print ('There are {} rows and {} columns.'.format(data_dim[0], data_dim[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 11: Prepare the test data using the same pipeline used from preparing the training data.\n",
    "1. Remove/exclude the unnecessary field(s) that will not contribute towards the prediction or will not go through pipelines.\n",
    "2. Run through the same pipeline used for training data.  This will impute any missing values and scale/encode the fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data2['Id']\n",
    "del data2['Alley']\n",
    "del data2['FireplaceQu']\n",
    "del data2['PoolQC']\n",
    "del data2['MiscFeature']\n",
    "del data2['MiscVal']\n",
    "del data2['Fence']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data    = data_prep_pipeline.transform(data2) #transform the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 12: Use the neural network to make predictions\n",
    "Now use the model to make predictions on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[120531.89],\n",
       "       [152652.44],\n",
       "       [187146.81],\n",
       "       ...,\n",
       "       [177374.27],\n",
       "       [121059.85],\n",
       "       [230045.83]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(test_data.toarray())\n",
    "Sample=ffnn_model.predict(X)\n",
    "Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 13: Summary\n",
    "Display samples of the predictions from your model and summarize your thoughts on the model's performance, the training process and its ability to generalize with new data. Are their any recommendations to improve the model in the future?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'>Summary</font>\n",
    "#### <font color='red'>Sample is already shown on previous cell!</font>\n",
    "####  <font color='blue'>Thoughts on model performance:</font>\n",
    "##### 1. Model seems to predict house prices quite right\n",
    "##### 2. Making a use of pipeline to scale and convert data is absolutely very useful to get a best accuracy for model\n",
    "##### 3. Overall, model definitely works better for making prediction. However, adding some more hidden layers and using different activations in model may have provided us with more accurate results!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
